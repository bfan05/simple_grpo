#!/usr/bin/env bash
set -euo pipefail

echo "=============================="
echo " RL BOX SETUP (DLAMI + CONDA)"
echo "=============================="

ENV_NAME="${ENV_NAME:-rl}"
PYTHON_VERSION="${PYTHON_VERSION:-3.10}"
TORCH_CUDA_INDEX_URL="${TORCH_CUDA_INDEX_URL:-https://download.pytorch.org/whl/cu121}"

CACHE_ROOT="${CACHE_ROOT:-/mnt/data}"
USE_MNT_DATA="false"
if [ -d "$CACHE_ROOT" ] && mountpoint -q "$CACHE_ROOT"; then
  USE_MNT_DATA="true"
fi

echo "Env: $ENV_NAME | Python: $PYTHON_VERSION"
echo "PyTorch index-url: $TORCH_CUDA_INDEX_URL"
echo "Cache root: $CACHE_ROOT (mounted: $USE_MNT_DATA)"

# -----------------------------
# System packages
# -----------------------------
echo "[1/9] Installing system packages..."
sudo apt-get update
sudo apt-get install -y \
  git tmux htop nvtop \
  build-essential \
  curl wget unzip \
  ca-certificates \
  python3-venv

# -----------------------------
# NVIDIA sanity check
# -----------------------------
echo "[2/9] Checking NVIDIA driver..."
command -v nvidia-smi >/dev/null 2>&1 || { echo "ERROR: nvidia-smi not found."; exit 1; }
nvidia-smi

# -----------------------------
# Conda availability
# -----------------------------
echo "[3/9] Ensuring conda is available..."
if command -v conda &>/dev/null; then
  echo "Found conda: $(which conda)"
else
  echo "conda not found; installing Miniconda..."
  CONDA_DIR="$HOME/miniconda3"
  wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh
  bash /tmp/miniconda.sh -b -p "$CONDA_DIR"
  rm /tmp/miniconda.sh
fi

# Make conda usable in non-interactive shells
# shellcheck disable=SC1091
source "$(conda info --base)/etc/profile.d/conda.sh"

# -----------------------------
# Create/activate environment
# -----------------------------
echo "[4/9] Creating/activating conda env..."
if ! conda env list | awk '{print $1}' | grep -qx "$ENV_NAME"; then
  conda create -y -n "$ENV_NAME" python="$PYTHON_VERSION"
fi
conda activate "$ENV_NAME"

python --version
pip install --upgrade pip setuptools wheel

# -----------------------------
# Put caches on big disk (if mounted)
# -----------------------------
echo "[5/9] Configuring caches..."
if [ "$USE_MNT_DATA" = "true" ]; then
  mkdir -p "$CACHE_ROOT/hf" "$CACHE_ROOT/torch" "$CACHE_ROOT/wandb" "$CACHE_ROOT/tmp"

  # Write a dedicated env file and source it from .bashrc exactly once
  ENV_SNIPPET="$HOME/.rl_box_env"
  cat > "$ENV_SNIPPET" << EOF
# Generated by setup_box.sh
export HF_HOME="$CACHE_ROOT/hf"
export TRANSFORMERS_CACHE="$CACHE_ROOT/hf/transformers"
export HF_DATASETS_CACHE="$CACHE_ROOT/hf/datasets"
export TORCH_HOME="$CACHE_ROOT/torch"
export WANDB_DIR="$CACHE_ROOT/wandb"
export TMPDIR="$CACHE_ROOT/tmp"
EOF

  if ! grep -q "source \$HOME/.rl_box_env" "$HOME/.bashrc" 2>/dev/null; then
    echo "" >> "$HOME/.bashrc"
    echo "# RL box env (added by setup_box.sh)" >> "$HOME/.bashrc"
    echo "source \$HOME/.rl_box_env" >> "$HOME/.bashrc"
  fi

  # Export for current shell too
  # shellcheck disable=SC1090
  source "$ENV_SNIPPET"
else
  echo "NOTE: $CACHE_ROOT not mounted. Caches will remain on root disk."
  echo "      After you mount your large EBS volume, rerun this script."
fi

# -----------------------------
# Install PyTorch (CUDA) + core stack
# -----------------------------
echo "[6/9] Installing PyTorch (CUDA wheel via pip)..."
pip install --upgrade torch torchvision torchaudio --index-url "$TORCH_CUDA_INDEX_URL"

python - << 'EOF'
import torch
print("Torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
print("CUDA version:", torch.version.cuda)
print("GPU:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)
EOF

# -----------------------------
# Install HF / TRL stack
# -----------------------------
echo "[7/9] Installing Hugging Face + TRL stack..."
pip install --upgrade \
  transformers datasets accelerate trl peft bitsandbytes sentencepiece \
  wandb evaluate numpy scipy packaging rich

# -----------------------------
# Optional: FlashAttention (best-effort)
# -----------------------------
echo "[8/9] Attempting FlashAttention install (optional, best-effort)..."
pip install flash-attn --no-build-isolation || echo "FlashAttention install failed; continuing."

# -----------------------------
# Accelerate default config
# -----------------------------
echo "[9/9] Writing accelerate config..."
ACCEL_DIR="$HOME/.cache/huggingface/accelerate"
mkdir -p "$ACCEL_DIR"
cat > "$ACCEL_DIR/default_config.yaml" << 'EOF'
compute_environment: LOCAL_MACHINE
distributed_type: NO
mixed_precision: bf16
use_cpu: false
num_processes: 1
num_machines: 1
machine_rank: 0
EOF

echo "=============================="
echo " SETUP COMPLETE"
echo "=============================="
echo "Run:"
echo "  source ~/.bashrc"
echo "  conda activate $ENV_NAME"
echo "  python -c \"import torch; print(torch.cuda.is_available())\""
echo "Tip: tmux new -s grpo"
